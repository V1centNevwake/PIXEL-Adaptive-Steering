
(.MS) (base) gpuser1@my-gpu-machine:~/MS$ python -m helpsteer.lasttoken_subspace_injection   --model meta-llama/Meta-Llama-3-8B-Instruct   --seed 20   --output runs/Reproduce/helpsteer/llama3_seed20_injection.jsonl   --baseline-output runs/Reproduce/helpsteer/llama3_seed20_baseline.jsonl   --max-probe 200 --num-samples 31 --layer-index 12   --z-target 0.85 --alpha-clip 0,200 --residual-scale 1   
/home/gpuser1/MS/.MS/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 322.76it/s]
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 1 | help=4 coh=4 verb=4 | avg_help=4.00
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 2 | help=4 coh=4 verb=4 | avg_help=4.00
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 3 | help=4 coh=4 verb=4 | avg_help=4.00
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 4 | help=4 coh=4 verb=4 | avg_help=4.00
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 5 | help=3 coh=3 verb=2 | avg_help=3.80
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 6 | help=4 coh=4 verb=4 | avg_help=3.83
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 7 | help=3 coh=3 verb=3 | avg_help=3.71
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 8 | help=4 coh=4 verb=4 | avg_help=3.75
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 9 | help=3 coh=3 verb=3 | avg_help=3.67
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 10 | help=4 coh=4 verb=4 | avg_help=3.70
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 11 | help=3 coh=3 verb=3 | avg_help=3.64
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 12 | help=3 coh=4 verb=3 | avg_help=3.58
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 13 | help=4 coh=4 verb=4 | avg_help=3.62
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 14 | help=4 coh=4 verb=4 | avg_help=3.64
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 15 | help=4 coh=4 verb=4 | avg_help=3.67
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 16 | help=4 coh=4 verb=4 | avg_help=3.69
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 17 | help=4 coh=4 verb=4 | avg_help=3.71
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Baseline | sample 18 | help=4 coh=4 verb=4 | avg_help=3.72
Baseline stop condition met at sample 18: avg_help=3.72 >= 3.7
Baseline finished with 18 samples | avg_help=3.72 avg_coh=3.78 avg_verb=3.67
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Layer 12 finished on 18 samples | avg_help=3.83 avg_coh=3.83 avg_verb=3.78
Δ vs baseline | help=+0.11 coh=+0.06 verb=+0.11
